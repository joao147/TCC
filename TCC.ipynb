{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424f4471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.1.74)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (2.26.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (1.20.3)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (4.6.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (0.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (3.2)\n",
      "Requirement already satisfied: ta in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\turen\\anaconda3\\lib\\site-packages (from ta) (1.20.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\turen\\anaconda3\\lib\\site-packages (from ta) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->ta) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->ta) (1.16.0)\n",
      "Requirement already satisfied: pandas_ta in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas_ta) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->pandas_ta) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Instal\n",
    "!pip install yfinance --upgrade --no-cache-dir\n",
    "# virtualenv -p python3 virtualenvironment\n",
    "# source virtualenvironment/bin/activate\n",
    "!pip install ta --upgrade --no-cache-dir\n",
    "!pip install pandas_ta --upgrade --no-cache-dir\n",
    "#imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import floor\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from ta.volatility import bollinger_mavg, KeltnerChannel\n",
    "\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfe8bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions\n",
    "\n",
    "#GET YAHOO DATA\n",
    "def get_data(ticker):    \n",
    "    ticker_data = web.get_data_yahoo(ticker, START_DATE, END_DATE)\n",
    "    return ticker_data\n",
    "\n",
    "def convert_data(ticker_data, ticker):\n",
    "    \n",
    "    names = []\n",
    "    table = []\n",
    "    \n",
    "    ticker_data = ticker_data.rename(columns = {ticker:'Close'})\n",
    "    for i in range(0, LOOP_MAX, SHIFT_DAYS) :\n",
    "        data = ticker_data[i:CORR_WINDOW + i]\n",
    "        date = data.index[0]\n",
    "        ticker_name = ticker + ' ' + date.strftime('%Y/%m/%d')\n",
    "        names.append(ticker_name)\n",
    "        data['Ticker'] = ticker_name\n",
    "        table.append(data)    \n",
    "        \n",
    "    return [names, table]\n",
    "\n",
    "#CREATE DATAFRAMES\n",
    "def create_dfs(datas_to_df):\n",
    "    dfs = []\n",
    "    for data_to_df in datas_to_df :\n",
    "        name, data = data_to_df\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.concat(data)\n",
    "        df = df.reset_index()\n",
    "        df = df.pivot(columns='Ticker',values='Close')\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "#PIVOT FUNCTIONS\n",
    "def pivot_df(df_pivot, data, names): \n",
    "    for i in range(floor(LOOP_MAX/SHIFT_DAYS)) :\n",
    "        column_name = names[i]\n",
    "        values = data[column_name].values\n",
    "        values = values[~np.isnan(values)]\n",
    "        values = pd.Series(values)\n",
    "        df_pivot.insert(len(df_pivot.columns), column_name, values)\n",
    "        \n",
    "    return df_pivot\n",
    "\n",
    "def pivot_all_dfs(dfs, datas):\n",
    "    dfs_pivoted = []\n",
    "    names = []\n",
    "    loop_times = len(dfs) - 1\n",
    "    \n",
    "    for j in range(loop_times):\n",
    "        for i in range(j, loop_times):\n",
    "            name_to_first = datas[j][0]\n",
    "            names_to_second = datas[i + 1][0]\n",
    "            names.append([name_to_first, names_to_second])\n",
    "            \n",
    "            df_pivoted = pd.DataFrame()\n",
    "            df_pivoted = pivot_df(df_pivoted, dfs[j], name_to_first)\n",
    "            df_pivoted = pivot_df(df_pivoted, dfs[i + 1], names_to_second)\n",
    "            dfs_pivoted.append(df_pivoted)\n",
    "        \n",
    "    return [dfs_pivoted, names]\n",
    "\n",
    "#CORRELATION FUNCTIONS\n",
    "def get_corr_df(df_pivot, nameRow, nameColumn):\n",
    "    #Using corr function to get correlation between actives\n",
    "    corr_df = df_pivot.corr(method='pearson')\n",
    "    #reset symbol as index (rather than 0-X)\n",
    "    corr_df.head().reset_index()\n",
    "    corr_df = corr_df.rename_axis(None, axis=0)\n",
    "    corr_df = corr_df.drop(nameRow, axis=1)\n",
    "    corr_df = corr_df.drop(nameColumn, axis=0)\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "def get_all_corr_dfs(dfs, names):\n",
    "    dfs_corr = []\n",
    "    for i in range(len(dfs)):\n",
    "        corr_df = get_corr_df(dfs[i], names[i][0], names[i][1])\n",
    "        dfs_corr.append(corr_df)\n",
    "    \n",
    "    return dfs_corr\n",
    "\n",
    "#INDICATOR FUNCTIONS\n",
    "def get_indicators(df):\n",
    "    values = df.values\n",
    "    means_df = pd.DataFrame()\n",
    "    deviations_df = pd.DataFrame()\n",
    "    columns_name = []\n",
    "    rang = floor(NUMBER_OF_TESTE/SHIFT_DAYS)\n",
    "    for i in range(rang):\n",
    "        means = []\n",
    "        deviations = []\n",
    "        row_name = df.index[i] + \" - \" + df.index[i + CORR_WINDOW].split(' ')[1] \n",
    "        for j in range(rang):\n",
    "            if i == 0:\n",
    "                column_name = df.columns[j] + \" - \" + df.columns[j + CORR_WINDOW].split(' ')[1] \n",
    "                columns_name.append(column_name)\n",
    "            ax = []\n",
    "            for k in range(CORR_WINDOW):\n",
    "                value = values[i+k][j+k]\n",
    "                ax.append(value)\n",
    "\n",
    "            mean = np.average(ax)\n",
    "            means.append(mean)\n",
    "\n",
    "            deviation = np.std(ax)\n",
    "            deviations.append(deviation)\n",
    "            \n",
    "        aux_df = pd.DataFrame([means], columns=columns_name, index=[row_name])\n",
    "        means_df = pd.concat([means_df, aux_df])\n",
    "        aux_df = pd.DataFrame([deviations], columns = columns_name, index=[row_name])\n",
    "        deviations_df = pd.concat([deviations_df, aux_df])\n",
    "        \n",
    "    return [means_df, deviations_df]\n",
    "\n",
    "def get_df_plot(dfs_corr):\n",
    "    means, deviations = get_indicators(dfs_corr)\n",
    "    \n",
    "    rang = len(means.index) - SHIFT_DAYS\n",
    "    values_means = means.values\n",
    "    values_deviations = deviations.values\n",
    "    values = []\n",
    "    columns = [1,2,3,4]\n",
    "    \n",
    "    for i in range(rang):\n",
    "        value = []\n",
    "        value_mean = values_means[i][i + SHIFT_DAYS]\n",
    "        value_deviation = values_deviations[i][i + SHIFT_DAYS]\n",
    "        value.append(value_mean)\n",
    "        value.append(value_deviation)\n",
    "        \n",
    "        value_mean = values_means[i + SHIFT_DAYS][i]\n",
    "        value_deviation = values_deviations[i + SHIFT_DAYS][i]\n",
    "        value.append(value_mean)\n",
    "        value.append(value_deviation)\n",
    "        \n",
    "        values.append(value)\n",
    "    columns = get_columns_name(means)    \n",
    "    final_df = pd.DataFrame(values, columns=columns)\n",
    "    return final_df\n",
    "\n",
    "def get_columns_name(df):\n",
    "    names = []\n",
    "    \n",
    "    for ind in [\"Means\", \"Deviations\"]:\n",
    "        ticker = df.columns[0].split(\" \")[0]\n",
    "        \n",
    "        index = df.index[0].split(\" \")\n",
    "        start_date = index[1]\n",
    "\n",
    "        last_index = df.index[len(df.index) - (SHIFT_DAYS + 1)].split(\" \") \n",
    "        end_date = last_index[1]\n",
    "        name = ind + \" - \"\n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date + \"\\n\"\n",
    "\n",
    "        index = df.index[1].split(\" \")\n",
    "        last_index = df.index[-1].split(\" \")\n",
    "        start_date = index[1]\n",
    "        end_date = last_index[1]\n",
    "        ticker = index[0]\n",
    "        \n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date\n",
    "        names.append(name)\n",
    "        \n",
    "    for ind in [\"Means\", \"Deviations\"]:\n",
    "        index = df.index[0].split(\" \")\n",
    "        start_date = index[1]\n",
    "        ticker = index[0]\n",
    "        last_index = df.index[len(df.index) - (SHIFT_DAYS + 1)].split(\" \") \n",
    "        end_date = last_index[1]\n",
    "        \n",
    "        name = ind + \" - \"\n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date + \"\\n\"\n",
    "\n",
    "        index = df.index[1].split(\" \")\n",
    "        last_index = df.index[-1].split(\" \")\n",
    "        start_date = index[1]\n",
    "        end_date = last_index[1]\n",
    "        ticker = df.columns[0].split(\" \")[0]\n",
    "        \n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date\n",
    "        names.append(name)\n",
    "        \n",
    "    return names\n",
    "\n",
    "def get_price_df(df_p, names):\n",
    "    df = pd.DataFrame()\n",
    "    dates = []\n",
    "    length = len(df_p[names[0]].columns)\n",
    "    \n",
    "    column = []    \n",
    "    ticker = names[0][0].split(\" \")[0]\n",
    "    for i in range(length):\n",
    "        dates.append(names[0][i].split(\" \")[1])\n",
    "        column.append(df_p[names[0]].values[0][i])\n",
    "    \n",
    "    df.insert(len(df.columns), ticker, column)\n",
    "    \n",
    "    column = []\n",
    "    ticker = names[1][0].split(\" \")[0]\n",
    "    for i in range(length):\n",
    "        column.append(df_p[names[1]].values[0][i])\n",
    "            \n",
    "    df.insert(len(df.columns), ticker, column) \n",
    "    \n",
    "    mavg = get_mavg(df)\n",
    "    df = df.join(mavg)\n",
    "    df.insert(0, \"Date\", dates)\n",
    "    return df\n",
    "\n",
    "def get_mavg(df):\n",
    "    mavg_df = pd.DataFrame()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        mavg_aux = bollinger_mavg(df[column], window=MAVG_WINDOW, fillna=True)\n",
    "        mavg_df.insert(len(mavg_df.columns),\"moving average of \" + column, mavg_aux)\n",
    "        \n",
    "    return mavg_df\n",
    "\n",
    "#Keltner Channel\n",
    "def get_KC(datas):    \n",
    "    high = []\n",
    "    close = []\n",
    "    low = []\n",
    "    lenght = len(datas[1])\n",
    "    data = datas[1]\n",
    "\n",
    "    for i in range(lenght):\n",
    "        high.append(data[i][\"High\"][0])\n",
    "        close.append(data[i][\"Close\"][0])\n",
    "        low.append(data[i][\"Low\"][0])\n",
    "\n",
    "    df_o = pd.DataFrame({\"High\": high, \"Close\": close, \"Low\": low})\n",
    "    \n",
    "    KC = KeltnerChannel(high=df_o[\"High\"], close=df_o[\"Close\"], low=df_o[\"Low\"], multiplier=MULTIPLIER, window=20, fillna=True)\n",
    "    \n",
    "    return KC\n",
    "\n",
    "def get_all_stocks_KC(data):\n",
    "    lenght = len(data)\n",
    "    dfs = []\n",
    "    for i in range(lenght):\n",
    "        ticker1 = tickers[i]\n",
    "        df_kc1 = get_KC(all_datas[i])\n",
    "        high1 = list(df_kc1.keltner_channel_hband())\n",
    "        low1 = list(df_kc1.keltner_channel_lband())\n",
    "        \n",
    "        for j in range(i+1, lenght):\n",
    "            ticker2 = tickers[j]\n",
    "            df_kc2 = get_KC(all_datas[j])\n",
    "            high2 = list(df_kc2.keltner_channel_hband())\n",
    "            low2 = list(df_kc2.keltner_channel_lband())\n",
    "            \n",
    "            df_aux = pd.DataFrame({ticker1 + \"-High\": high1, ticker1 + \"-Low\": low1, \n",
    "                                   ticker2 + \"-High\": high2, ticker2 + \"-Low\": low2})\n",
    "            dfs.append(df_aux)\n",
    "            \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4101c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "#Fazer mais simulações\n",
    "SHIFT_DAYS = 1\n",
    "CORR_WINDOW = 9 # 5,7,9\n",
    "MAVG_WINDOW = 42 # 36,38,40,42\n",
    "MULTIPLIER = 1 # 1,2,3\n",
    "ENTER_CORR = 0.7\n",
    "\n",
    "START_DATE = datetime(2014, 1, 1)\n",
    "END_DATE = datetime(2016, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d06e2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "tickers = ['ENBR3.SA','VALE3.SA','ITUB3.SA','BBAS3.SA','BBSE3.SA', 'PSSA3.SA']\n",
    "len_tickers = len(tickers)\n",
    "range_len_tickers = range(len_tickers)\n",
    "\n",
    "loaded_datas = get_data(tickers)\n",
    "\n",
    "LOOP_MAX = len(loaded_datas) - CORR_WINDOW - SHIFT_DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "578d0d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>14.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>14.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>14.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>14.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>14.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22</th>\n",
       "      <td>14.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-23</th>\n",
       "      <td>15.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>14.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>14.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>14.395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close\n",
       "Date              \n",
       "2014-01-02  14.680\n",
       "2014-01-03  14.640\n",
       "2014-01-06  14.475\n",
       "2014-01-07  14.405\n",
       "2014-01-08  14.180\n",
       "...            ...\n",
       "2015-12-22  14.935\n",
       "2015-12-23  15.165\n",
       "2015-12-28  14.775\n",
       "2015-12-29  14.515\n",
       "2015-12-30  14.395\n",
       "\n",
       "[494 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdff = pd.DataFrame(loaded_datas[\"Close\"][ticker])\n",
    "pdff = pdff.rename(columns = {ticker:'Close'})\n",
    "pdff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffa804b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turen\\AppData\\Local\\Temp/ipykernel_4800/3565085142.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ticker'] = ticker_name\n",
      "C:\\Users\\turen\\AppData\\Local\\Temp/ipykernel_4800/1642147322.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs_pivoted, names = pivot_all_dfs(dfs, all_data)\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = convert_data(pd.DataFrame(loaded_datas[\"Close\"][ticker]), ticker)\n",
    "    all_data.append(data)\n",
    "    \n",
    "dfs = create_dfs(all_data)\n",
    "    \n",
    "#Pivoting table to aggregate active price in a line of each date\n",
    "dfs_pivoted, names = pivot_all_dfs(dfs, all_data)\n",
    "\n",
    "dfs_corr = get_all_corr_dfs(dfs_pivoted, names)\n",
    "\n",
    "len_dfs_corr = len(dfs_corr)\n",
    "range_len_dfs_corr = range(len_dfs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for corr_window in [5,7,9]:\n",
    "#     CORR_WINDOW = corr_window\n",
    "#     LOOP_MAX = len(loaded_datas) - CORR_WINDOW - SHIFT_DAYS\n",
    "#     for i in range_len_tickers:\n",
    "#         dfs = create_dfs(all_datas[i], tickers[i])\n",
    "        \n",
    "#     dfs_pivoted, names = pivot_all_dfs(dfs, all_datas)\n",
    "\n",
    "#     dfs_corr = get_all_corr_dfs(dfs_pivoted, names)\n",
    "    \n",
    "#     for i in range_len_dfs_corr:\n",
    "#         aux_ind = get_df_plot(dfs_corr[i])\n",
    "#         indicators_dfs.append(aux_ind)\n",
    "        \n",
    "#     for mavg_window in [36,38,40,42]:\n",
    "#         MAVG_WINDOW = mavg_window\n",
    "        \n",
    "#         for i in range_len_dfs_corr:\n",
    "#             price_df = get_price_df(dfs_pivoted[i], names[i])\n",
    "#             prices_dfs.append(price_df)\n",
    "            \n",
    "#         for multiplier in [1,2,3]:\n",
    "#             MULTIPLIER = multiplier\n",
    "            \n",
    "#             dfs_kc = get_all_stocks_KC(all_datas)\n",
    "            \n",
    "#             for enter_corr in [0.66,0.68,0.7,0.72]:\n",
    "#                 ENTER_CORR = enter_corr\n",
    "                \n",
    "#                 for i in range_len_dfs_corr:\n",
    "#                     equity_curve = pd.DataFrame(columns=['Date', 'Profit'])\n",
    "                    \n",
    "#                     equity_aux = trade_comprado(indicators_dfs[i], prices_dfs[i], dfs_kc[i])\n",
    "#                     equity_curve = pd.concat([equity_curve, equity_aux], ignore_index=True)\n",
    "                    \n",
    "#                     equity_aux = trade_vendido(indicators_dfs[i], prices_dfs[i], dfs_kc[i])\n",
    "#                     equity_curve = pd.concat([equity_curve, equity_aux], ignore_index=True)\n",
    "                    \n",
    "#                     equity_curve = pd.DataFrame(equity_curve.groupby(['Date']).Profit.sum().cumsum())\n",
    "                    \n",
    "#                     final_profit = list(equity_curve['Profit'].values)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81830916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, corr_ax = plt.subplots()\n",
    "indicators_dfs = []\n",
    "prices_dfs = []\n",
    "\n",
    "for i in range_len_dfs_corr:\n",
    "    aux_ind = get_df_plot(dfs_corr[i])\n",
    "    indicators_dfs.append(aux_ind)\n",
    "    \n",
    "    price_df = get_price_df(dfs_pivoted[i], names[i])\n",
    "    prices_dfs.append(price_df)\n",
    "\n",
    "# for i in range(2): \n",
    "#     mean = final_df.columns[i * 2]\n",
    "#     deviation = final_df.columns[(i * 2) + 1]\n",
    "#     plt.fill_between(final_df.index, final_df[mean] - final_df[deviation], final_df[mean] + final_df[deviation], alpha=0.2)\n",
    "#     final_df.plot(y=mean,figsize=(10,10), xlim=[0, len(final_df[mean]) - 1], ylim=[-1,1], grid=True, ax=corr_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_kc = get_all_stocks_KC(all_datas)\n",
    "\n",
    "# fig, price_ax = plt.subplots()\n",
    "\n",
    "# price_df.plot(figsize=(10,10), xlim=[0, len(price_df) - 1], grid=True, ax=price_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_comprado(corr_df, price_df, kcs_df):#Culva de equity\n",
    "    equity = pd.DataFrame(columns=['Date', 'Profit'])\n",
    "    \n",
    "#     lost_corr = ENTER_CORR - 0.1\n",
    "    enter_corr = ENTER_CORR\n",
    "    \n",
    "#     stop_lose = 0.06\n",
    "    \n",
    "    price_length = len(price_df.index)\n",
    "    corr_length = len(corr_df.index)\n",
    "    corr_relation = floor(price_length / corr_length)\n",
    "    \n",
    "    date = price_df.columns[0]\n",
    "    dates = price_df[date]\n",
    "    \n",
    "    stock_a = price_df.columns[1]\n",
    "    stock_b = price_df.columns[2]\n",
    "    stock_a_mavg = price_df.columns[3]\n",
    "    stock_b_mavg = price_df.columns[4]\n",
    "    \n",
    "    stock_a_predicting_mean_corr = corr_df.columns[0]\n",
    "    stock_a_predicting_desviation_corr = corr_df.columns[1]\n",
    "    stock_b_predicting_mean_corr = corr_df.columns[2]\n",
    "    stock_b_predicting_desviation_corr = corr_df.columns[3]\n",
    "    \n",
    "    stock_a_high_kc = kcs_df.columns[0]\n",
    "    stock_a_low_kc = kcs_df.columns[1]\n",
    "    stock_b_high_kc = kcs_df.columns[2]\n",
    "    stock_b_low_kc = kcs_df.columns[3]\n",
    "    \n",
    "    file = open(path_comprado, \"a+\")\n",
    "    \n",
    "    for g in range(2):\n",
    "        \n",
    "        nmb_stock = 0\n",
    "        nmb_orders = 0\n",
    "        paid_stock = 0\n",
    "        money = 1000\n",
    "        sell_cause = \"\"\n",
    "        bought = False\n",
    "        \n",
    "        title = \"Using {0} to predict {1}\\n\".format(stock_a, stock_b)\n",
    "        file.write(title)\n",
    "        \n",
    "        for i in range(price_length):\n",
    "            stock_price = price_df[stock_b][i]\n",
    "            \n",
    "            aux = floor(i / corr_relation)\n",
    "            if aux >= corr_length:\n",
    "                aux = corr_length - 1\n",
    "                \n",
    "            if bought:\n",
    "                if stock_price > kcs_df[stock_b_high_kc][i]:\n",
    "                    sell_cause = \"Better than KC\"\n",
    "                    bought = False\n",
    "                if price_df[stock_a][i] < price_df[stock_a_mavg][i]:\n",
    "                    sell_cause = \"{0} is low than mavg\".format(stock_a)\n",
    "                    bought = False\n",
    "#                 if corr_df[stock_b_predicting_mean_corr][aux] < lost_corr:#testar sem este IF\n",
    "#                     sell_cause = \"Lost correlation\"\n",
    "#                     bought = False\n",
    "#                 if stock_price <= paid_stock * (1 - stop_lose):\n",
    "#                     sell_cause = \"Stop, lost {0}%\".format(stop_lose * 100)\n",
    "#                     bought = False\n",
    "\n",
    "                if not bought:\n",
    "                    if(nmb_stock > 0):\n",
    "                        profit = ((stock_price * nmb_stock) - (paid_stock * nmb_stock))\n",
    "                        EC_aux = pd.DataFrame([{\"Date\": dates[i], \"Profit\": profit}])\n",
    "                        equity = equity.append(EC_aux)\n",
    "                    money += stock_price * nmb_stock\n",
    "                    nmb_stock = 0\n",
    "                    file.write(\"selling in {0} - money: {1} - cause:{2}\\n\".format(dates[i], money, sell_cause))#stonk prices\n",
    "                    nmb_orders += 1\n",
    "            else:\n",
    "                if price_df[stock_a][i] > price_df[stock_a_mavg][i]:\n",
    "                    if stock_price < price_df[stock_b_mavg][i]:\n",
    "                        if corr_df[stock_b_predicting_mean_corr][aux] > enter_corr:\n",
    "                            bought = True\n",
    "                            nmb_stock = floor(money/stock_price)\n",
    "                            money = money%stock_price\n",
    "                            paid_stock = stock_price\n",
    "                            file.write(\"buying in {0} - money: {1}, stocks: {2}\\n\".format(dates[i], money, nmb_stock))\n",
    "                            nmb_orders += 1\n",
    "        file.write(\"Money in final of tests {0} and Number of orders {1}\\n\\n\".format(money, nmb_orders))\n",
    "        \n",
    "        stock_a = price_df.columns[2]\n",
    "        stock_b = price_df.columns[1]\n",
    "        stock_a_mavg = price_df.columns[4]\n",
    "        stock_b_mavg = price_df.columns[3]\n",
    "        \n",
    "        stock_a_predicting_mean_corr = corr_df.columns[2]\n",
    "        stock_a_predicting_desviation_corr = corr_df.columns[3]\n",
    "        stock_b_predicting_mean_corr = corr_df.columns[0]\n",
    "        stock_b_predicting_desviation_corr = corr_df.columns[1]\n",
    "        \n",
    "        stock_a_high_kc = kcs_df.columns[2]\n",
    "        stock_a_low_kc = kcs_df.columns[3]\n",
    "        stock_b_high_kc = kcs_df.columns[0]\n",
    "        stock_b_low_kc = kcs_df.columns[1]\n",
    "    \n",
    "    file.close()\n",
    " \n",
    "    return equity\n",
    "\n",
    "def trade_vendido(corr_df, price_df, kcs_df):\n",
    "    equity = pd.DataFrame(columns=['Date', 'Profit'])\n",
    "    \n",
    "#     lost_corr = ENTER_CORR - 0.1\n",
    "    enter_corr = ENTER_CORR\n",
    "    \n",
    "#     stop_lose = 0.06\n",
    "    \n",
    "    price_length = len(price_df.index)\n",
    "    corr_length = len(corr_df.index)\n",
    "    corr_relation = floor(price_length / corr_length)\n",
    "    \n",
    "    date = price_df.columns[0]\n",
    "    dates = price_df[date]\n",
    "    \n",
    "    stock_a = price_df.columns[1]\n",
    "    stock_b = price_df.columns[2]\n",
    "    stock_a_mavg = price_df.columns[3]\n",
    "    stock_b_mavg = price_df.columns[4]\n",
    "    \n",
    "    stock_a_predicting_mean_corr = corr_df.columns[0]\n",
    "    stock_a_predicting_desviation_corr = corr_df.columns[1]\n",
    "    stock_b_predicting_mean_corr = corr_df.columns[2]\n",
    "    stock_b_predicting_desviation_corr = corr_df.columns[3]\n",
    "    \n",
    "    stock_a_high_kc = kcs_df.columns[0]\n",
    "    stock_a_low_kc = kcs_df.columns[1]\n",
    "    stock_b_high_kc = kcs_df.columns[2]\n",
    "    stock_b_low_kc = kcs_df.columns[3]\n",
    "    \n",
    "    file = open(path_vendido, \"a+\")\n",
    "    \n",
    "    for g in range(2):\n",
    "        \n",
    "        nmb_stock = 0\n",
    "        nmb_orders = 0\n",
    "        sold_stock = 0\n",
    "        money = 1000\n",
    "        purchase_cause = \"\"\n",
    "        sold = True\n",
    "        \n",
    "        title = \"Using {0} to predict {1}\\n\".format(stock_a, stock_b)\n",
    "        file.write(title)\n",
    "        \n",
    "        for i in range(1, price_length):\n",
    "            stock_price = price_df[stock_b][i]\n",
    "            \n",
    "            aux = floor(i / corr_relation)\n",
    "            if aux >= corr_length:\n",
    "                aux = corr_length - 1\n",
    "            \n",
    "            if sold:\n",
    "                if stock_price < kcs_df[stock_b_low_kc][i]:\n",
    "                    purchase_cause = \"Lower than KC\"\n",
    "                    sold = False\n",
    "                if price_df[stock_a][i] > price_df[stock_a_mavg][i]:\n",
    "                    purchase_cause = \"{0} is better than mavg\".format(stock_a)\n",
    "                    sold = False\n",
    "#                 if corr_df[stock_b_predicting_mean_corr][aux] < lost_corr:#testar sem este IF\n",
    "#                     purchase_cause = \"Lost correlation\"\n",
    "#                     sold = False\n",
    "#                 if stock_price >= sold_stock * (1 - stop_lose):\n",
    "#                     purchase_cause = \"Stop, lost {0}%\".format(stop_lose * 100)\n",
    "#                     sold = False\n",
    "\n",
    "                if not sold:\n",
    "                    nmb_stock = floor(money/stock_price)\n",
    "                    money = money%stock_price\n",
    "                    if(sold_stock != 0):\n",
    "                        profit = ((sold_stock * nmb_stock) - (stock_price * nmb_stock))\n",
    "                        EC_aux = pd.DataFrame([{\"Date\": dates[i], \"Profit\": profit}])\n",
    "                        equity = equity.append(EC_aux)\n",
    "                    file.write(\"Buying in {0} - money: {1},  stocks: {2} - cause:{3}\\n\".format(dates[i], money, nmb_stock, purchase_cause))\n",
    "                    nmb_orders += 1\n",
    "                \n",
    "            else:\n",
    "                if price_df[stock_a][i] < price_df[stock_a_mavg][i]:\n",
    "                    if stock_price > price_df[stock_b_mavg][i]:\n",
    "                        if corr_df[stock_b_predicting_mean_corr][aux] > enter_corr:\n",
    "                            sold = True\n",
    "                            money += stock_price * nmb_stock\n",
    "                            nmb_stock = 0\n",
    "                            sold_stock = stock_price\n",
    "                            file.write(\"Selling in {0} - money: {1}\\n\".format(dates[i], money))\n",
    "                            nmb_orders += 1\n",
    "                            \n",
    "        file.write(\"Money in final of tests {0} and Number of orders {1}\\n\\n\".format(money, nmb_orders))\n",
    "        \n",
    "        stock_a = price_df.columns[2]\n",
    "        stock_b = price_df.columns[1]\n",
    "        stock_a_mavg = price_df.columns[4]\n",
    "        stock_b_mavg = price_df.columns[3]\n",
    "        \n",
    "        stock_a_predicting_mean_corr = corr_df.columns[2]\n",
    "        stock_a_predicting_desviation_corr = corr_df.columns[3]\n",
    "        stock_b_predicting_mean_corr = corr_df.columns[0]\n",
    "        stock_b_predicting_desviation_corr = corr_df.columns[1]\n",
    "        \n",
    "        stock_a_high_kc = kcs_df.columns[2]\n",
    "        stock_a_low_kc = kcs_df.columns[3]\n",
    "        stock_b_high_kc = kcs_df.columns[0]\n",
    "        stock_b_low_kc = kcs_df.columns[1]\n",
    "    \n",
    "    file.close()\n",
    "    return equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89443abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testes\n",
    "\n",
    "# equity_curve = pd.DataFrame(data=[{\"Date\": \"2021/07/11\", \"Profit\": -10},{\"Date\": \"2022/05/12\", \"Profit\": 50}, {\"Date\": \"2020/06/11\", \"Profit\": 20}],columns=['Date', 'Profit'])\n",
    "# EC_aux = pd.DataFrame([{\"Date\": \"2022/06/11\", \"Profit\": -15}])\n",
    "# equity_curve = pd.concat([equity_curve, EC_aux])\n",
    "# equity_curve.sort_values(by='Date')\n",
    "# equity_curve = pd.DataFrame(equity_curve.groupby(['Date']).Profit.sum().cumsum())\n",
    "# equity_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_comprado = \"trade_comprado.txt\"\n",
    "path_vendido = \"trade_vendido.txt\"\n",
    "\n",
    "if os.path.exists(path_comprado):\n",
    "    os.remove(path_comprado)\n",
    "if os.path.exists(path_vendido):\n",
    "    os.remove(path_vendido)\n",
    "\n",
    "equity_curve = pd.DataFrame(columns=['Date', 'Profit'])\n",
    "\n",
    "for i in range_len_dfs_corr:\n",
    "    equity_aux = trade_comprado(indicators_dfs[i], prices_dfs[i], dfs_kc[i])\n",
    "    equity_curve = pd.concat([equity_curve, equity_aux], ignore_index=True)\n",
    "    equity_aux = trade_vendido(indicators_dfs[i], prices_dfs[i], dfs_kc[i])\n",
    "    equity_curve = pd.concat([equity_curve, equity_aux], ignore_index=True)\n",
    "    \n",
    "equity_curve = pd.DataFrame(equity_curve.groupby(['Date']).Profit.sum().cumsum())\n",
    "equity_curve\n",
    "\n",
    "fig, equity_ax = plt.subplots()\n",
    "\n",
    "equity_curve.plot(figsize=(10,10), xlim=[0, len(equity_curve) - 1], grid=True, ax=equity_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a7145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
