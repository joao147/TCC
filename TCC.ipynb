{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "424f4471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.1.72)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (1.20.3)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (4.6.3)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (2.26.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (1.3.4)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from yfinance) (0.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: ta in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\turen\\anaconda3\\lib\\site-packages (from ta) (1.20.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\turen\\anaconda3\\lib\\site-packages (from ta) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->ta) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->ta) (1.16.0)\n",
      "Requirement already satisfied: pandas_ta in c:\\users\\turen\\anaconda3\\lib\\site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas_ta) (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\turen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->pandas_ta) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Instal\n",
    "!pip install yfinance --upgrade --no-cache-dir\n",
    "# virtualenv -p python3 virtualenvironment\n",
    "# source virtualenvironment/bin/activate\n",
    "!pip install ta --upgrade --no-cache-dir\n",
    "!pip install pandas_ta --upgrade --no-cache-dir\n",
    "#imports\n",
    "import yfinance as yf\n",
    "\n",
    "from ta.volatility import bollinger_mavg\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas_ta as ta\n",
    "from ta.volatility import KeltnerChannel\n",
    "\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dfe8bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions\n",
    "\n",
    "#GET YAHOO DATA\n",
    "def get_data(ticker):\n",
    "    date = DATE\n",
    "    \n",
    "    names = []\n",
    "    table = []\n",
    "    all_data = []\n",
    "    aux_date = 0\n",
    "    length_test = 0\n",
    "    \n",
    "    while length_test < LOOP_MAX + CORR_WINDOW:\n",
    "        final_date = date + timedelta(days=(LOOP_MAX + SHIFT_DAYS + CORR_WINDOW + aux_date))\n",
    "        all_data = web.get_data_yahoo(ticker, date, final_date)\n",
    "        aux_date = aux_date + 20\n",
    "        length_test = len(all_data)\n",
    "        \n",
    "    for i in range(0,LOOP_MAX, SHIFT_DAYS) :\n",
    "        data = all_data[i:CORR_WINDOW + i]\n",
    "        date = data.index[0]\n",
    "        ticker_name = ticker + ' ' + date.strftime('%Y/%m/%d')\n",
    "        names.append(ticker_name)\n",
    "        data['Ticker'] = ticker_name\n",
    "        table.append(data)    \n",
    "        \n",
    "    return [names, table]\n",
    "\n",
    "#CREATE DATAFRAMES\n",
    "def create_dfs(datas_to_df):\n",
    "    dfs = []\n",
    "    for data_to_df in datas_to_df :\n",
    "        name, data = data_to_df\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.concat(data)\n",
    "        df = df.reset_index()\n",
    "        df = df.pivot(columns='Ticker',values='Close')\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "#PIVOT FUNCTIONS\n",
    "def pivot_df(df_pivot, data, names): \n",
    "    for i in range(floor(LOOP_MAX/SHIFT_DAYS)) :\n",
    "        column_name = names[i]\n",
    "        values = data[column_name].values\n",
    "        values = values[~np.isnan(values)]\n",
    "        values = pd.Series(values)\n",
    "        df_pivot.insert(len(df_pivot.columns), column_name, values)\n",
    "        \n",
    "    return df_pivot\n",
    "\n",
    "def pivot_all_dfs(dfs, datas):\n",
    "    dfs_pivoted = []\n",
    "    names = []\n",
    "    loop_times = len(dfs) - 1\n",
    "    \n",
    "    for j in range(loop_times):\n",
    "        for i in range(j, loop_times):\n",
    "            name_to_first = datas[j][0]\n",
    "            names_to_second = datas[i + 1][0]\n",
    "            names.append([name_to_first, names_to_second])\n",
    "            \n",
    "            df_pivoted = pd.DataFrame()\n",
    "            df_pivoted = pivot_df(df_pivoted, dfs[j], name_to_first)\n",
    "            df_pivoted = pivot_df(df_pivoted, dfs[i + 1], names_to_second)\n",
    "            dfs_pivoted.append(df_pivoted)\n",
    "        \n",
    "    return [dfs_pivoted, names]\n",
    "\n",
    "#CORRELATION FUNCTIONS\n",
    "def get_corr_df(df_pivot, nameRow, nameColumn):\n",
    "    #Using corr function to get correlation between actives\n",
    "    corr_df = df_pivot.corr(method='pearson')\n",
    "    #reset symbol as index (rather than 0-X)\n",
    "    corr_df.head().reset_index()\n",
    "    corr_df = corr_df.rename_axis(None, axis=0)\n",
    "    corr_df = corr_df.drop(nameRow, axis=1)\n",
    "    corr_df = corr_df.drop(nameColumn, axis=0)\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "def get_all_corr_dfs(dfs, names):\n",
    "    dfs_corr = []\n",
    "    for i in range(len(dfs)):\n",
    "        corr_df = get_corr_df(dfs[i], names[i][0], names[i][1])\n",
    "        dfs_corr.append(corr_df)\n",
    "    \n",
    "    return dfs_corr\n",
    "\n",
    "#INDICATOR FUNCTIONS\n",
    "def get_indicators(df):\n",
    "    values = df.values\n",
    "    means_df = pd.DataFrame()\n",
    "    deviations_df = pd.DataFrame()\n",
    "    columns_name = []\n",
    "    rang = floor(NUMBER_OF_TESTE/SHIFT_DAYS)\n",
    "    for i in range(rang):\n",
    "        means = []\n",
    "        deviations = []\n",
    "        row_name = df.index[i] + \" - \" + df.index[i + CORR_WINDOW].split(' ')[1] \n",
    "        for j in range(rang):\n",
    "            if i == 0:\n",
    "                column_name = df.columns[j] + \" - \" + df.columns[j + CORR_WINDOW].split(' ')[1] \n",
    "                columns_name.append(column_name)\n",
    "            aux = []\n",
    "            for k in range(CORR_WINDOW):\n",
    "                value = values[i+k][j+k]\n",
    "                aux.append(value)\n",
    "\n",
    "            mean = np.average(aux)\n",
    "            means.append(mean)\n",
    "\n",
    "            deviation = np.std(aux)\n",
    "            deviations.append(deviation)\n",
    "            \n",
    "        aux_df = pd.DataFrame([means], columns=columns_name, index=[row_name])\n",
    "        means_df = pd.concat([means_df, aux_df])\n",
    "        aux_df = pd.DataFrame([deviations], columns = columns_name, index=[row_name])\n",
    "        deviations_df = pd.concat([deviations_df, aux_df])\n",
    "        \n",
    "    return [means_df, deviations_df]\n",
    "\n",
    "def get_df_plot(dfs_corr):\n",
    "    means, deviations = get_indicators(dfs_corr)\n",
    "    \n",
    "    rang = len(means.index) - SHIFT_DAYS\n",
    "    values_means = means.values\n",
    "    values_deviations = deviations.values\n",
    "    values = []\n",
    "    columns = [1,2,3,4]\n",
    "    \n",
    "    for i in range(rang):\n",
    "        value = []\n",
    "        value_mean = values_means[i][i + SHIFT_DAYS]\n",
    "        value_deviation = values_deviations[i][i + SHIFT_DAYS]\n",
    "        value.append(value_mean)\n",
    "        value.append(value_deviation)\n",
    "        \n",
    "        value_mean = values_means[i + SHIFT_DAYS][i]\n",
    "        value_deviation = values_deviations[i + SHIFT_DAYS][i]\n",
    "        value.append(value_mean)\n",
    "        value.append(value_deviation)\n",
    "        \n",
    "        values.append(value)\n",
    "    columns = get_columns_name(means)    \n",
    "    final_df = pd.DataFrame(values, columns=columns)\n",
    "    return final_df\n",
    "\n",
    "def get_columns_name(df):\n",
    "    names = []\n",
    "    \n",
    "    for ind in [\"Means\", \"Deviations\"]:\n",
    "        ticker = df.columns[0].split(\" \")[0]\n",
    "        \n",
    "        index = df.index[0].split(\" \")\n",
    "        start_date = index[1]\n",
    "\n",
    "        last_index = df.index[len(df.index) - (SHIFT_DAYS + 1)].split(\" \") \n",
    "        end_date = last_index[1]\n",
    "        name = ind + \" - \"\n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date + \"\\n\"\n",
    "\n",
    "        index = df.index[1].split(\" \")\n",
    "        last_index = df.index[-1].split(\" \")\n",
    "        start_date = index[1]\n",
    "        end_date = last_index[1]\n",
    "        ticker = index[0]\n",
    "        \n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date\n",
    "        names.append(name)\n",
    "        \n",
    "    for ind in [\"Means\", \"Deviations\"]:\n",
    "        index = df.index[0].split(\" \")\n",
    "        start_date = index[1]\n",
    "        ticker = index[0]\n",
    "        last_index = df.index[len(df.index) - (SHIFT_DAYS + 1)].split(\" \") \n",
    "        end_date = last_index[1]\n",
    "        \n",
    "        name = ind + \" - \"\n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date + \"\\n\"\n",
    "\n",
    "        index = df.index[1].split(\" \")\n",
    "        last_index = df.index[-1].split(\" \")\n",
    "        start_date = index[1]\n",
    "        end_date = last_index[1]\n",
    "        ticker = df.columns[0].split(\" \")[0]\n",
    "        \n",
    "        name = name + ticker + \" start at \"\n",
    "        name = name + start_date + \" unitl \"\n",
    "        name = name + end_date\n",
    "        names.append(name)\n",
    "        \n",
    "    return names\n",
    "\n",
    "def get_price_df(df_p, names):\n",
    "    df = pd.DataFrame()\n",
    "    dates = []\n",
    "    length = len(df_p[names[0]].columns)\n",
    "    \n",
    "    column = []    \n",
    "    ticker = names[0][0].split(\" \")[0]\n",
    "    for i in range(length):\n",
    "        dates.append(names[0][i].split(\" \")[1])\n",
    "        for j in range(SHIFT_DAYS):\n",
    "            column.append(df_p[names[0]].values[j][i])\n",
    "    \n",
    "    df.insert(len(df.columns), ticker, column)\n",
    "    \n",
    "    column = []\n",
    "    ticker = names[1][0].split(\" \")[0]\n",
    "    for i in range(length):\n",
    "        for j in range(SHIFT_DAYS):\n",
    "            column.append(df_p[names[1]].values[j][i])\n",
    "            \n",
    "    df.insert(len(df.columns), ticker, column) \n",
    "    \n",
    "    mavg = get_mavg(df)\n",
    "    df = df.join(mavg)\n",
    "    df.insert(0, \"Date\", dates)\n",
    "    return df\n",
    "\n",
    "def get_mavg(df):\n",
    "    mavg_df = pd.DataFrame()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        mavg_aux = bollinger_mavg(df[column], window=MAVG_WINDOW, fillna=True)\n",
    "        mavg_df.insert(len(mavg_df.columns),\"moving average of \" + column, mavg_aux)\n",
    "        \n",
    "    return mavg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4101c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "#Fazer mais simulações\n",
    "SHIFT_DAYS = 1 # 1 2 3\n",
    "CORR_WINDOW = 7 # 5 7 9\n",
    "MAVG_WINDOW = 36 # 36 38 40\n",
    "NUMBER_OF_TESTE = 126\n",
    "\n",
    "DATE = datetime(2021, 1, 4)\n",
    "\n",
    "LOOP_MAX = NUMBER_OF_TESTE * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06e2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turen\\AppData\\Local\\Temp/ipykernel_10620/3340368960.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ticker'] = ticker_name\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "all_datas = []\n",
    "tickers = ['ENBR3.SA','VALE3.SA','ITUB3.SA','BBAS3.SA','VIIA3.SA','MGLU3.SA']\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = get_data(ticker)\n",
    "    all_datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa804b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turen\\AppData\\Local\\Temp/ipykernel_10620/2807483580.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs_pivoted, names = pivot_all_dfs(dfs, all_datas)\n"
     ]
    }
   ],
   "source": [
    "dfs = create_dfs(all_datas)\n",
    "#Pivoting table to aggregate active price in a line of each date\n",
    "dfs_pivoted, names = pivot_all_dfs(dfs, all_datas)\n",
    "\n",
    "dfs_corr = get_all_corr_dfs(dfs_pivoted, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81830916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, corr_ax = plt.subplots()\n",
    "indicators_dfs = []\n",
    "prices_dfs = []\n",
    "\n",
    "for i in range(len(dfs_corr)):\n",
    "    aux_ind = get_df_plot(dfs_corr[i])\n",
    "    indicators_dfs.append(aux_ind)\n",
    "    \n",
    "    price_df = get_price_df(dfs_pivoted[i], names[i])\n",
    "    prices_dfs.append(price_df)\n",
    "    \n",
    "# for i in range(2): \n",
    "#     mean = final_df.columns[i * 2]\n",
    "#     deviation = final_df.columns[(i * 2) + 1]\n",
    "#     plt.fill_between(final_df.index, final_df[mean] - final_df[deviation], final_df[mean] + final_df[deviation], alpha=0.2)\n",
    "#     final_df.plot(y=mean,figsize=(10,10), xlim=[0, len(final_df[mean]) - 1], ylim=[-1,1], grid=True, ax=corr_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1871d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, price_ax = plt.subplots()\n",
    "\n",
    "# price_df.plot(figsize=(10,10), xlim=[0, len(price_df) - 1], grid=True, ax=price_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57d32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade(corr_df, price_df):#Operar vendido\n",
    "    lost_corr = 0.55\n",
    "    enter_corr = 0.65\n",
    "    \n",
    "    stop_lose = 0.05\n",
    "    \n",
    "    money_a = 1000\n",
    "    money_b = 1000\n",
    "    nmb_stock = 0\n",
    "    nmb_orders_a = 0\n",
    "    nmb_orders_b = 0\n",
    "    paid_stock_a = 0\n",
    "    paid_stock_b = 0\n",
    "    bought = False\n",
    "    \n",
    "    price_length = len(price_df.index)\n",
    "    corr_length = len(corr_df.index)\n",
    "    corr_relation = floor(price_length / corr_length)\n",
    "    \n",
    "    date = price_df.columns[0]\n",
    "    dates = price_df[date]\n",
    "    \n",
    "    stock_a = price_df.columns[1]\n",
    "    stock_b = price_df.columns[2]\n",
    "    stock_a_mavg = price_df.columns[3]\n",
    "    stock_b_mavg = price_df.columns[4]\n",
    "    \n",
    "    stock_a_predicting_mean_corr = corr_df.columns[0]\n",
    "    stock_a_predicting_desviation_corr = corr_df.columns[1]\n",
    "    stock_b_predicting_mean_corr = corr_df.columns[2]\n",
    "    stock_b_predicting_desviation_corr = corr_df.columns[3]\n",
    "    \n",
    "    file = open(\"trade.txt\", \"a+\")\n",
    "    title = \"Using {0} to predict {1}\\n\".format(stock_a, stock_b)\n",
    "    file.write(title)\n",
    "    for i in range(len(price_df.index)):\n",
    "        if bought:\n",
    "            stock_price = price_df[stock_b][i]\n",
    "            if stock_price > price_df[stock_b_mavg][i]:#mudar add kc/envelope\n",
    "                money_b = money_b + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif price_df[stock_a][i] < price_df[stock_a_mavg][i]:\n",
    "                money_b = money_b + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif corr_df[stock_b_predicting_mean_corr][aux] < lost_corr:\n",
    "                money_b = money_b + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif stock_price <= paid_stock_b * (1 - stop_lose):\n",
    "                money_b = money_b + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            if not bought:\n",
    "                file.write(\"selling in {0} - money: {1}\\n\".format(dates[i], money_b))\n",
    "                nmb_orders_b += 1\n",
    "        else:\n",
    "            if price_df[stock_a][i] > price_df[stock_a_mavg][i]:\n",
    "                if price_df[stock_b][i] < price_df[stock_b_mavg][i]:\n",
    "                    aux = floor(i / corr_relation)\n",
    "                    if aux >= corr_length:\n",
    "                        aux = corr_length - 1\n",
    "                    if corr_df[stock_b_predicting_mean_corr][aux] > enter_corr:\n",
    "                        bought = True\n",
    "                        stock_price = price_df[stock_b][i]\n",
    "                        nmb_stock = floor(money_b/stock_price)\n",
    "                        money_b = money_b%stock_price\n",
    "                        paid_stock_b = stock_price\n",
    "                        file.write(\"buying in {0} - money: {1}, stocks: {2}\\n\".format(dates[i], money_b, nmb_stock))\n",
    "                        nmb_orders_b += 1\n",
    "    file.write(\"Money in final of tests {0} and Number of orders {1}\\n\\n\".format(money_b, nmb_orders_b))\n",
    "    title = \"Using {0} to predict {1}\\n\".format(stock_b, stock_a)\n",
    "    file.write(title)\n",
    "    \n",
    "    bought = False\n",
    "    for i in range(len(price_df.index)):\n",
    "        if bought:\n",
    "            stock_price = price_df[stock_b][i]\n",
    "            if stock_price > price_df[stock_a_mavg][i]:\n",
    "                money_a = money_a + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif price_df[stock_b][i] < price_df[stock_b_mavg][i]:\n",
    "                money_a = money_a + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif corr_df[stock_a_predicting_mean_corr][aux] < lost_corr :\n",
    "                money_a = money_a + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            elif stock_price <= paid_stock_a * (1 - stop_lose):\n",
    "                money_b = money_b + stock_price * nmb_stock\n",
    "                nmb_stock = 0\n",
    "                bought = False\n",
    "            if not bought:\n",
    "                file.write(\"selling in {0} - money:{1}\\n\".format(dates[i], money_a))\n",
    "                nmb_orders_a += 1\n",
    "        else:\n",
    "            if price_df[stock_b][i] > price_df[stock_b_mavg][i]:\n",
    "                if price_df[stock_a][i] < price_df[stock_a_mavg][i]:\n",
    "                    aux = floor(i / corr_relation)\n",
    "                    if aux >= corr_length:\n",
    "                        aux = corr_length - 1\n",
    "                    if corr_df[stock_a_predicting_mean_corr][aux] > enter_corr:\n",
    "                        bought = True\n",
    "                        stock_price = price_df[stock_b][i]\n",
    "                        paid_stock_a = stock_price\n",
    "                        nmb_stock = floor(money_a/stock_price)\n",
    "                        money_a = money_a%stock_price\n",
    "                        file.write(\"buying in {0} - money: {1}, stocks: {2}\\n\".format(dates[i], money_a, nmb_stock))\n",
    "                        nmb_orders_a += 1\n",
    "    file.write(\"Money in final of tests {0} and Number of orders {1}\\n\\n\".format(money_a, nmb_orders_a))\n",
    "    file.close()                    \n",
    "    return {stock_b: money_b, stock_a: money_a}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f090d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs_corr)):\n",
    "    trade(indicators_dfs[i], prices_dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c361074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(\"trade.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28eafb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "high = []\n",
    "close = []\n",
    "low = []\n",
    "lenght = len(all_datas[0][1])\n",
    "data = all_datas[0][1]\n",
    "\n",
    "for i in range(lenght):\n",
    "    high.append(data[i][\"High\"][0])\n",
    "    close.append(data[i][\"Close\"][0])\n",
    "    low.append(data[i][\"Low\"][0])\n",
    "\n",
    "    \n",
    "df_o = pd.DataFrame({\"High\": high, \"Close\": close, \"Low\": low})\n",
    "df_final = KeltnerChannel(high=df_o[\"High\"], close=df_o[\"Close\"], low=df_o[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b32f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      20.233333\n",
       "1      19.880000\n",
       "2      19.735555\n",
       "3      19.620000\n",
       "4      19.699999\n",
       "         ...    \n",
       "247    21.477500\n",
       "248    21.444333\n",
       "249    21.366833\n",
       "250    21.271833\n",
       "251    21.189833\n",
       "Name: kc_hband, Length: 252, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.keltner_channel_hband()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
